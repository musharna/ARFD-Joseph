---
title: "ARFD_RNAseq_Analysis"
output: html_document
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

## Load Required Libraries

```{r libraries}
# Install packages if needed (uncomment as needed)
# BiocManager::install(c("DESeq2", "org.At.tair.db", "clusterProfiler", "GOSemSim"))
# install.packages(c("dplyr", "ggplot2", "pheatmap", "svglite", "ggrepel", "tidyr", "UpSetR", "eulerr"))

library(dplyr)
library(pheatmap)
library(ggplot2)
library(svglite)
library(DESeq2)
library(tidyr)
```

## Configuration - EDIT THIS SECTION

```{r configuration}
# =============================================================================
# CONFIGURATION - Modify these settings for your data
# =============================================================================

# Path to your featureCounts output file
counts_file <- "gene_counts.txt"

# Sample metadata - maps sample numbers to construct names
# Format: sample_number, construct_name, replicate
sample_metadata <- data.frame(
  sample_num = sprintf("%02d", 1:28),
  construct = c(
    "GUS", "GUS_aux", "5D", "6D", "7D", "8D", "19D",      # Replicate 1
    "GUS", "GUS_aux", "5D", "6D", "7D", "8D", "19D",      # Replicate 2
    "GUS", "GUS_aux", "5D", "6D", "7D", "8D", "19D",      # Replicate 3
    "GUS", "GUS_aux", "5D", "6D", "7D", "8D", "19D"       # Replicate 4
  ),
  replicate = c(
    rep(1, 7), rep(2, 7), rep(3, 7), rep(4, 7)
  ),
  stringsAsFactors = FALSE
)

# Create sample names in format "Construct-Replicate" (e.g., "GUS-1", "5D-2")
sample_metadata$sample_name <- paste0(sample_metadata$construct, "-", sample_metadata$replicate)

# Define control construct (for differential expression comparisons)
control_construct <- "GUS"

# All constructs in order (control first, then treatments)
all_constructs <- c("GUS", "GUS_aux", "5D", "6D", "7D", "8D", "19D")

# Constructs to compare against control (excluding the control itself)
treatment_constructs <- c("GUS_aux", "5D", "6D", "7D", "8D", "19D")

# DEG thresholds
padj_threshold <- 0.01      # Adjusted p-value cutoff
lfc_threshold <- 1          # Log2 fold change cutoff (absolute value)
min_avg_reads <- 20         # Minimum average normalized reads filter

# Number of samples to use (samples 1-28 based on your input)
n_samples <- 28

# Outlier samples to exclude (sample numbers as integers)
outlier_samples <- c(1, 10, 11, 16, 19, 20, 21)
```

## Data Import and Preprocessing

```{r import_data}
# Read featureCounts output (skip the first comment line)
raw_counts <- read.table(counts_file, header = TRUE, sep = "\t",
                         skip = 1, check.names = FALSE, stringsAsFactors = FALSE)

# Extract gene annotation columns
gene_info <- raw_counts[, c("Geneid", "Chr", "Start", "End", "Strand", "Length")]

# Extract count columns (columns 7 onwards are the sample counts)
# Get column names and select only the first n_samples
count_cols <- colnames(raw_counts)[7:ncol(raw_counts)]

# Filter to only keep the samples we need (1-28)
keep_samples <- grep(paste0("24250R-01-(", paste(sprintf("%02d", 1:n_samples), collapse = "|"), ")_"),
                     count_cols, value = TRUE)

# Extract counts matrix
counts_matrix <- as.matrix(raw_counts[, keep_samples])
rownames(counts_matrix) <- raw_counts$Geneid

# Simplify column names to just sample numbers
colnames(counts_matrix) <- gsub(".*24250R-01-([0-9]+)_.*", "\\1", colnames(counts_matrix))

# Remove outlier samples from metadata and counts matrix
outlier_nums <- sprintf("%02d", outlier_samples)
sample_metadata <- sample_metadata[!sample_metadata$sample_num %in% outlier_nums, ]
counts_matrix <- counts_matrix[, !colnames(counts_matrix) %in% outlier_nums]

# Reorder columns to match sample_metadata order
counts_matrix <- counts_matrix[, sample_metadata$sample_num]

# Rename columns to descriptive sample names
colnames(counts_matrix) <- sample_metadata$sample_name

cat("Dimensions of counts matrix:", dim(counts_matrix), "\n")
cat("Outliers removed:", paste(outlier_nums, collapse = ", "), "\n")
cat("Sample names:", colnames(counts_matrix), "\n")
```

## Quality Control Plots

```{r qc_plots, fig.width=10, fig.height=6}
# Calculate library sizes
lib_sizes <- colSums(counts_matrix)

# Create a barplot of library sizes
lib_size_df <- data.frame(
  Sample = names(lib_sizes),
  Reads = lib_sizes,
  Construct = sample_metadata$construct
)

ggplot(lib_size_df, aes(x = Sample, y = Reads/1e6, fill = Construct)) +
  geom_bar(stat = "identity") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "Sample", y = "Million Reads", title = "Library Sizes")

# PCA on raw counts (after log transformation)
log_counts <- log2(counts_matrix + 1)

# Remove zero-variance genes before PCA (constant rows can't be scaled)
gene_vars <- apply(log_counts, 1, var)
log_counts_filtered <- log_counts[gene_vars > 0, ]

pca_result <- prcomp(t(log_counts_filtered), scale. = TRUE)

pca_df <- data.frame(
  PC1 = pca_result$x[,1],
  PC2 = pca_result$x[,2],
  Sample = rownames(pca_result$x),
  Construct = sample_metadata$construct
)

ggplot(pca_df, aes(x = PC1, y = PC2, color = Construct, label = Sample)) +
  geom_point(size = 3) +
  geom_text(vjust = -0.5, size = 3) +
  theme_bw() +
  labs(title = "PCA of Raw Counts (log2 transformed)")
```

## DESeq2 Normalization and Differential Expression

```{r deseq2_analysis}
# Create DESeq2 dataset
col_data <- data.frame(
  row.names = sample_metadata$sample_name,
  construct = factor(sample_metadata$construct, levels = all_constructs),
  replicate = factor(sample_metadata$replicate)
)

dds <- DESeqDataSetFromMatrix(
  countData = counts_matrix,
  colData = col_data,
  design = ~ construct
)

# Pre-filter low-count genes
keep <- rowSums(counts(dds) >= 10) >= 3
dds <- dds[keep, ]

# Run DESeq2
dds <- DESeq(dds)

# Get normalized counts
norm_counts <- counts(dds, normalized = TRUE)
```

## Compute Average Normalized Reads per Construct

```{r compute_averages}
# Create a data frame to hold all results
df <- data.frame(Geneid = rownames(norm_counts))

# Add normalized counts for each sample
for (i in 1:ncol(norm_counts)) {
  df[[colnames(norm_counts)[i]]] <- norm_counts[, i]
}

# Compute average normalized reads for each construct
for (con in all_constructs) {
  # Find all columns that match this construct
  cols <- grep(paste0("^", con, "-\\d+$"), names(df), value = TRUE)
  avg_col <- paste0("avg_reads-", con)
  df[[avg_col]] <- rowMeans(df[, cols, drop = FALSE], na.rm = TRUE)
}

# Save normalized counts with averages
write.csv(df, file = "ARFD_normalized_counts_with_averages.csv", row.names = FALSE, quote = TRUE)

cat("Created average columns for constructs:", all_constructs, "\n")
```

## Differential Expression Analysis

```{r differential_expression}
# Extract DE results for each treatment vs control
de_results_list <- list()

for (con in treatment_constructs) {
  # Get DESeq2 results
  res <- results(dds, contrast = c("construct", con, control_construct))
  res_df <- as.data.frame(res)
  res_df$Geneid <- rownames(res_df)

  # Rename columns to include construct name
  colnames(res_df)[colnames(res_df) == "log2FoldChange"] <- paste0("log2FoldChange-", con)
  colnames(res_df)[colnames(res_df) == "pvalue"] <- paste0("pvalue-", con)
  colnames(res_df)[colnames(res_df) == "padj"] <- paste0("padj-", con)
  colnames(res_df)[colnames(res_df) == "baseMean"] <- paste0("baseMean-", con)
  colnames(res_df)[colnames(res_df) == "lfcSE"] <- paste0("lfcSE-", con)
  colnames(res_df)[colnames(res_df) == "stat"] <- paste0("stat-", con)

  de_results_list[[con]] <- res_df
}

# Merge all DE results with the normalized counts
df2 <- df
for (con in treatment_constructs) {
  res_df <- de_results_list[[con]]
  cols_to_add <- setdiff(colnames(res_df), "Geneid")
  df2 <- merge(df2, res_df[, c("Geneid", cols_to_add)], by = "Geneid", all.x = TRUE)
}
```

## Classify Up/Down Regulated Genes

```{r classify_updown}
# Define control average reads column
control_col <- paste0("avg_reads-", control_construct)

# Loop over treatment constructs to classify Up/Down
for (con in treatment_constructs) {
  l2fc_col <- paste0("log2FoldChange-", con)
  padj_col <- paste0("padj-", con)
  avg_col <- paste0("avg_reads-", con)
  up_down_col <- paste0("Up_Down-", con)

  # Classify based on thresholds:
  # - padj < threshold
  # - |log2FoldChange| > lfc_threshold
  # - average reads for treatment OR control > min_avg_reads
  df2[[up_down_col]] <- ifelse(
    !is.na(df2[[padj_col]]) &
      df2[[padj_col]] < padj_threshold &
      abs(df2[[l2fc_col]]) > lfc_threshold &
      (df2[[avg_col]] > min_avg_reads | df2[[control_col]] > min_avg_reads),
    ifelse(df2[[l2fc_col]] > 0, "UP", "Down"),
    ""
  )
}

# Save results
write.csv(df2, file = paste0("ARFD_DE_results_LFC", lfc_threshold, "_p",
                              gsub("\\.", "", as.character(padj_threshold)), ".csv"),
          row.names = FALSE, quote = TRUE)

# Print summary
cat("\n=== Differential Expression Summary ===\n")
for (con in treatment_constructs) {
  up_down_col <- paste0("Up_Down-", con)
  n_up <- sum(df2[[up_down_col]] == "UP", na.rm = TRUE)
  n_down <- sum(df2[[up_down_col]] == "Down", na.rm = TRUE)
  cat(sprintf("%s: %d UP, %d Down\n", con, n_up, n_down))
}
```

## Generate Heatmaps

### All DEGs Heatmap

```{r heatmap_all_degs, fig.width=10, fig.height=8}
# Define Up/Down columns
ud_cols <- paste0("Up_Down-", treatment_constructs)

# Filter for any gene that is UP or Down in at least one construct
df_DEGs <- df2 %>%
  filter(if_any(all_of(ud_cols), ~ . %in% c("UP", "Down")))

cat("Total DEGs across all constructs:", nrow(df_DEGs), "\n")

# Define constructs for heatmap (include control)
constructs_for_heatmap <- all_constructs
counts_cols <- paste0("avg_reads-", constructs_for_heatmap)

# Create heatmap matrix
df_heat <- df_DEGs %>%
  dplyr::select(all_of(counts_cols)) %>%
  as.matrix()
rownames(df_heat) <- df_DEGs$Geneid

# Remove rows with all zeros or NAs
df_heat <- df_heat[rowSums(df_heat, na.rm = TRUE) > 0, ]
df_heat <- df_heat[complete.cases(df_heat), ]

if (nrow(df_heat) > 0) {
  # Elbow method for k-means clustering
  WSS <- numeric(14)
  for (k in 2:15) {
    set.seed(123)
    km <- kmeans(df_heat, centers = k, nstart = 25, iter.max = 30)
    WSS[k - 1] <- km$tot.withinss
  }

  svglite("K-means_all_DEGs.svg", width = 10, height = 7)
  plot(2:15, WSS,
       type = "b",
       xlab = "# of Clusters (K)",
       ylab = "Total within-clusters sum of squares",
       main = "Elbow Method for k-means")
  dev.off()

  # Create heatmap
  svglite("All_DEGs_heatmap.svg", width = 10, height = 8)
  heat_all <- pheatmap(
    df_heat,
    scale = "row",
    show_rownames = FALSE,
    show_colnames = TRUE,
    cluster_cols = FALSE,
    cluster_rows = TRUE,
    cutree_rows = 9,
    main = "All DEGs Heatmap"
  )
  dev.off()

  # Display heatmap in notebook
  pheatmap(
    df_heat,
    scale = "row",
    show_rownames = FALSE,
    show_colnames = TRUE,
    cluster_cols = FALSE,
    cluster_rows = TRUE,
    cutree_rows = 9,
    main = "All DEGs Heatmap"
  )
}
```

### Extract Gene Clusters

```{r extract_clusters}
if (exists("heat_all") && !is.null(heat_all$tree_row)) {
  # Get cluster assignments
  clusters <- cutree(heat_all$tree_row, k = 9)
  annotation_df <- data.frame(Cluster = factor(clusters))
  rownames(annotation_df) <- names(clusters)

  # Create heatmap with cluster annotation
  svglite("All_DEGs_heatmap_clustered.svg", width = 10, height = 8)
  pheatmap(
    df_heat,
    scale = "row",
    show_rownames = FALSE,
    show_colnames = TRUE,
    cluster_cols = FALSE,
    cluster_rows = TRUE,
    cutree_rows = 9,
    annotation_row = annotation_df,
    main = "All DEGs with Cluster Annotations"
  )
  dev.off()

  # Save cluster assignments
  row_clust <- data.frame(
    GeneID = names(clusters),
    Cluster = clusters
  )
  write.csv(row_clust, file = "gene_clusters.csv", row.names = FALSE, quote = TRUE)

  # Merge cluster info back to main results
  df2 <- merge(df2, row_clust, by.x = "Geneid", by.y = "GeneID", all.x = TRUE)
  write.csv(df2, file = paste0("ARFD_DE_results_LFC", lfc_threshold, "_p",
                                gsub("\\.", "", as.character(padj_threshold)), "_clustered.csv"),
            row.names = FALSE, quote = TRUE)

  cat("\nGenes per cluster:\n")
  print(table(row_clust$Cluster))
}
```

### Cluster Comparison with Joseph's Analysis

```{r cluster_comparison, fig.width=10, fig.height=8}
# install.packages("readxl")
library(readxl)

# Candidate files to look for (checked in order; first match wins)
joseph_candidates <- c(
  "ARFD_Up_Down_Regulated_LFC-1_p01_clustered(1).csv",
  "ARFD_Up_Down_Regulated_LFC-1_p01_clustered.csv",
  "ARF567 clusters.xlsx",
  "ARF567 clusters.xlxs"   # typo variant
)

joseph_file <- NA_character_
for (f in joseph_candidates) {
  if (file.exists(f)) { joseph_file <- f; break }
}

if (!is.na(joseph_file) && "Cluster" %in% colnames(df2)) {

  # Load depending on file type
  if (grepl("\\.csv$", joseph_file, ignore.case = TRUE)) {
    joseph_clusters <- read.csv(joseph_file, check.names = FALSE, stringsAsFactors = FALSE)
  } else {
    joseph_clusters <- read_excel(joseph_file)
  }
  cat("Using reference file:", joseph_file, "\n")

  # Diagnostics: show what columns and how many genes are in Joseph's file
  cat("=== Joseph's file diagnostics ===\n")
  cat("Columns in Joseph's file:", paste(colnames(joseph_clusters), collapse = ", "), "\n")
  cat("Rows in Joseph's file:", nrow(joseph_clusters), "\n")
  cat("Rows in your clustered DEGs:", nrow(df2 %>% filter(!is.na(Cluster))), "\n")

  # Confirm expected columns exist
  if ("Geneid" %in% colnames(joseph_clusters) && "Gene_Cluster" %in% colnames(joseph_clusters)) {

    # Show unique clusters in Joseph's file before joining
    cat("Unique clusters in Joseph's file:", sort(unique(joseph_clusters$Gene_Cluster)), "\n")

    # Normalise gene IDs to uppercase for robust matching
    my_genes_df <- df2 %>%
      dplyr::select(Geneid, Cluster) %>%
      filter(!is.na(Cluster)) %>%
      mutate(Geneid = toupper(trimws(Geneid)))

    joseph_genes_df <- joseph_clusters %>%
      dplyr::select(Geneid, Joseph_Cluster = Gene_Cluster) %>%
      mutate(Geneid = toupper(trimws(Geneid)))

    # Report overlap before joining
    cat("Your unique gene IDs (first 5):", paste(head(my_genes_df$Geneid, 5), collapse = ", "), "\n")
    cat("Joseph's unique gene IDs (first 5):", paste(head(joseph_genes_df$Geneid, 5), collapse = ", "), "\n")
    genes_in_common <- intersect(my_genes_df$Geneid, joseph_genes_df$Geneid)
    cat("Genes in common (exact ID match):", length(genes_in_common), "\n")
    cat("Genes only in your set:", nrow(my_genes_df) - length(genes_in_common), "\n")
    cat("Genes only in Joseph's set:", nrow(joseph_genes_df) - length(genes_in_common), "\n")

    # Join on Geneid - keep only genes present in both datasets
    cluster_comparison <- my_genes_df %>%
      inner_join(joseph_genes_df, by = "Geneid")

    cat("\nGenes found in both datasets:", nrow(cluster_comparison), "\n")

    # === Cross-tabulation table ===
    cross_tab <- table(
      My_Cluster    = cluster_comparison$Cluster,
      Joseph_Cluster = cluster_comparison$Joseph_Cluster
    )
    cat("\nCluster overlap counts (rows = your clusters, cols = Joseph's clusters):\n")
    print(cross_tab)

    # === Normalised heatmap (proportion of each of YOUR clusters in Joseph's) ===
    cross_mat <- as.matrix(cross_tab)
    # Normalise each row so colours show what fraction of your cluster maps to each Joseph cluster
    cross_norm <- cross_mat / rowSums(cross_mat)

    # Only attempt heatmaps when there are >=2 rows AND >=2 cols AND value variation exists
    # (pheatmap's cut() fails when all values are identical, e.g. single-column matrix all = 1)
    can_heatmap <- nrow(cross_norm) >= 2 && ncol(cross_norm) >= 2

    if (can_heatmap) {
      svglite("Cluster_Comparison_Heatmap.svg", width = 10, height = 8)
      pheatmap(
        cross_norm,
        cluster_rows = nrow(cross_norm) > 1,
        cluster_cols = ncol(cross_norm) > 1,
        display_numbers = cross_mat,   # show raw counts on cells
        number_format = "%d",
        color = colorRampPalette(c("white", "#2C748E", "#440F57"))(50),
        main = "Cluster Overlap: Your Clusters (rows) vs Joseph's Clusters (cols)\n(colour = proportion, numbers = gene count)",
        fontsize_number = 9
      )
      dev.off()

      pheatmap(
        cross_norm,
        cluster_rows = nrow(cross_norm) > 1,
        cluster_cols = ncol(cross_norm) > 1,
        display_numbers = cross_mat,
        number_format = "%d",
        color = colorRampPalette(c("white", "#2C748E", "#440F57"))(50),
        main = "Cluster Overlap: Your Clusters (rows) vs Joseph's Clusters (cols)\n(colour = proportion, numbers = gene count)",
        fontsize_number = 9
      )
    } else {
      cat("\nNote: Cross-tabulation heatmap skipped — Joseph's file contains only 1 unique cluster.\n")
      cat("Raw counts table printed above shows all overlap information.\n")
    }

    # === Jaccard similarity for each pair of clusters ===
    my_clusters      <- sort(unique(cluster_comparison$Cluster))
    joseph_clusters_ids <- sort(unique(cluster_comparison$Joseph_Cluster))

    jaccard_mat <- matrix(0,
                          nrow = length(my_clusters),
                          ncol = length(joseph_clusters_ids),
                          dimnames = list(my_clusters, joseph_clusters_ids))

    for (mc in my_clusters) {
      for (jc in joseph_clusters_ids) {
        genes_mine   <- cluster_comparison$Geneid[cluster_comparison$Cluster == mc]
        genes_joseph <- cluster_comparison$Geneid[cluster_comparison$Joseph_Cluster == jc]
        intersection <- length(intersect(genes_mine, genes_joseph))
        union_size   <- length(union(genes_mine, genes_joseph))
        jaccard_mat[as.character(mc), as.character(jc)] <- intersection / union_size
      }
    }

    cat("\nJaccard similarity matrix (your clusters vs Joseph's):\n")
    print(round(jaccard_mat, 3))

    can_jaccard_heatmap <- nrow(jaccard_mat) >= 2 && ncol(jaccard_mat) >= 2

    if (can_jaccard_heatmap) {
      # Plot Jaccard heatmap
      svglite("Cluster_Comparison_Jaccard.svg", width = 10, height = 8)
      pheatmap(
        jaccard_mat,
        cluster_rows = nrow(jaccard_mat) > 1,
        cluster_cols = ncol(jaccard_mat) > 1,
        display_numbers = TRUE,
        number_format = "%.2f",
        color = colorRampPalette(c("white", "#37B977", "#440F57"))(50),
        main = "Jaccard Similarity: Your Clusters (rows) vs Joseph's Clusters (cols)"
      )
      dev.off()

      pheatmap(
        jaccard_mat,
        cluster_rows = nrow(jaccard_mat) > 1,
        cluster_cols = ncol(jaccard_mat) > 1,
        display_numbers = TRUE,
        number_format = "%.2f",
        color = colorRampPalette(c("white", "#37B977", "#440F57"))(50),
        main = "Jaccard Similarity: Your Clusters (rows) vs Joseph's Clusters (cols)"
      )
    } else {
      cat("\nNote: Jaccard heatmap skipped — only 1 unique Joseph cluster. Jaccard values above show per-cluster overlap fractions.\n")
    }

    # Save full mapping table
    write.csv(cluster_comparison,
              file = "Cluster_Comparison_Gene_Mapping.csv",
              row.names = FALSE, quote = TRUE)

    cat("\nBest matching Joseph cluster for each of your clusters:\n")
    best_match <- apply(jaccard_mat, 1, function(x) {
      data.frame(Best_Joseph_Cluster = names(which.max(x)),
                 Jaccard = round(max(x), 3))
    })
    print(do.call(rbind, best_match))

  } else {
    cat("Expected columns 'Geneid' and 'Gene_Cluster' not found in Joseph's file.\n")
    cat("Columns found:", paste(colnames(joseph_clusters), collapse = ", "), "\n")
  }
} else if (is.na(joseph_file)) {
  cat("Reference cluster file not found. Place one of the following in the working directory:\n")
  cat("  - ARFD_Up_Down_Regulated_LFC-1_p01_clustered(1).csv\n")
  cat("  - ARF567 clusters.xlsx\n")
} else {
  cat("Cluster column not yet available in df2. Run the heatmap clustering section first.\n")
}
```

### DEG Recovery Analysis — Why Were Joseph's DEGs Missed?

```{r deg_recovery_analysis, fig.width=12, fig.height=8}
# Requires: joseph_clusters loaded above, de_results_list (full DESeq2 results), df2
if (!is.na(joseph_file) && exists("joseph_clusters") &&
    "Geneid" %in% colnames(joseph_clusters) && exists("de_results_list")) {

  # --- Diagnostics: show what we're working with ---
  ud_j <- grep("^Up_Down-", colnames(joseph_clusters), value = TRUE)
  ud_m <- grep("^Up_Down-", colnames(df2), value = TRUE)
  cat("Up_Down columns in Joseph's file:\n"); cat(" ", paste(ud_j, collapse="\n  "), "\n")
  cat("Up_Down columns in our df2:\n");        cat(" ", paste(ud_m, collapse="\n  "), "\n")
  cat("treatment_constructs:", paste(treatment_constructs, collapse=", "), "\n\n")

  # Explicit mapping: our construct code → suffix used in Joseph's columns
  # (derived from the Up_Down column names printed above)
  j_suffix_map <- c(
    "GUS_aux" = "GUSaux_A",
    "5D"      = "5D_A",
    "6D"      = "6D_A",
    "7D"      = "7D_A",
    "8D"      = "8D_A",
    "19D"     = "19D_A"
  )

  construct_map <- data.frame(
    my_code  = treatment_constructs,
    j_suffix = j_suffix_map[treatment_constructs],
    stringsAsFactors = FALSE
  )

  cat("Construct mapping (our code → Joseph's column suffix):\n")
  print(construct_map)
  cat("\n")

  recovery_rows  <- list()
  missed_detail  <- list()

  for (i in seq_len(nrow(construct_map))) {
    con       <- construct_map$my_code[i]
    j_suffix  <- construct_map$j_suffix[i]
    con_label <- con   # use raw code; update below if mapping found

    if (is.na(j_suffix)) {
      cat("No matching column found in Joseph's file for construct:", con, "\n")
      next
    }

    j_col  <- paste0("Up_Down-",        j_suffix)
    j_lfc  <- paste0("log2FoldChange-", j_suffix)
    j_padj <- paste0("padj-",           j_suffix)
    my_col <- paste0("Up_Down-",        con)

    if (!j_col %in% colnames(joseph_clusters)) {
      cat("Column not found in Joseph's file:", j_col, "(available:", paste(ud_j, collapse=", "), ")\n")
      next
    }

    # Joseph DEGs for this construct
    j_up   <- joseph_ids[!is.na(joseph_clusters[[j_col]]) & joseph_clusters[[j_col]] == "UP"]
    j_down <- joseph_ids[!is.na(joseph_clusters[[j_col]]) & joseph_clusters[[j_col]] == "Down"]
    j_degs <- union(j_up, j_down)

    # Our DEGs (from df2 Up_Down col)
    my_up   <- toupper(trimws(df2$Geneid[!is.na(df2[[my_col]]) & df2[[my_col]] == "UP"]))
    my_down <- toupper(trimws(df2$Geneid[!is.na(df2[[my_col]]) & df2[[my_col]] == "Down"]))
    my_degs <- union(my_up, my_down)

    missed <- setdiff(j_degs, my_degs)

    recovery_rows[[con]] <- data.frame(
      Construct    = con_label,
      Joseph_UP    = length(j_up),
      My_UP        = length(my_up),
      Joseph_Down  = length(j_down),
      My_Down      = length(my_down),
      Missed_total = length(missed),
      Recovery_pct = round(100 * length(intersect(j_degs, my_degs)) / max(length(j_degs), 1), 1),
      stringsAsFactors = FALSE
    )

    # --- Categorise each missed gene using OUR full DESeq2 results ---
    full_res <- de_results_list[[con]]
    if (!is.null(full_res)) {
      lfc_col_full  <- paste0("log2FoldChange-", con)
      padj_col_full <- paste0("padj-", con)

      # Keep only the columns needed — avoids rbind failure from construct-specific names
      full_res <- full_res %>%
        mutate(Geneid_upper = toupper(trimws(Geneid))) %>%
        filter(Geneid_upper %in% missed) %>%
        dplyr::select(Geneid_upper,
                      my_lfc  = all_of(lfc_col_full),
                      my_padj = all_of(padj_col_full))

      # Also pull Joseph's LFC for these missed genes
      joseph_lfc_vals <- joseph_clusters %>%
        mutate(Geneid_upper = toupper(trimws(Geneid))) %>%
        filter(Geneid_upper %in% missed) %>%
        dplyr::select(Geneid_upper,
                      joseph_lfc  = all_of(j_lfc),
                      joseph_padj = all_of(j_padj))

      detail <- full_res %>%
        left_join(joseph_lfc_vals, by = "Geneid_upper") %>%
        mutate(
          Construct = con_label,
          Category = case_when(
            is.na(my_lfc)                              ~ "Not in our data (low counts/filtered)",
            is.na(my_padj) | my_padj > padj_threshold ~ "Padj too high (not significant)",
            abs(my_lfc) < lfc_threshold                ~ paste0("LFC below threshold (|LFC| < ", lfc_threshold, ")"),
            TRUE                                       ~ "Other / direction flip"
          )
        )
      missed_detail[[con]] <- detail
    }
  }

  # --- Summary table ---
  recovery_df <- dplyr::bind_rows(recovery_rows)
  cat("=== DEG Recovery Summary ===\n")
  print(as.data.frame(recovery_df))

  # --- Stacked bar: category breakdown of missed DEGs per construct ---
  detail_all <- dplyr::bind_rows(missed_detail)

  if (!is.null(detail_all) && nrow(detail_all) > 0) {
    cat_counts <- detail_all %>%
      dplyr::count(Construct, Category) %>%
      dplyr::group_by(Construct) %>%
      dplyr::mutate(Pct = round(100 * n / sum(n), 1))

    p_bar <- ggplot(cat_counts, aes(x = Construct, y = n, fill = Category)) +
      geom_col(position = "stack") +
      geom_text(aes(label = ifelse(n > 30, n, "")),
                position = position_stack(vjust = 0.5), size = 3, colour = "white") +
      scale_fill_brewer(palette = "Set2") +
      labs(title = "Why Were Joseph's DEGs Not Recovered?",
           subtitle = paste0("Genes called DEG by Joseph but NOT by our analysis ",
                             "(LFC≥", lfc_threshold, ", padj≤", padj_threshold, ")"),
           x = NULL, y = "Number of missed genes", fill = "Reason") +
      theme_bw(base_size = 13) +
      theme(legend.position = "right")

    print(p_bar)
    ggsave("DEG_Recovery_Breakdown.svg", p_bar, width = 10, height = 6)

    # --- LFC comparison scatter per construct ---
    # For missed genes where we have our own LFC, plot Joseph LFC vs Our LFC
    scatter_data <- detail_all %>%
      dplyr::mutate(joseph_lfc = as.numeric(joseph_lfc)) %>%
      dplyr::filter(!is.na(my_lfc) & !is.na(joseph_lfc))

    if (nrow(scatter_data) > 0) {
      p_scatter <- ggplot(scatter_data,
                          aes(x = joseph_lfc, y = my_lfc, colour = Category)) +
        geom_point(alpha = 0.4, size = 1.2) +
        geom_hline(yintercept =  c(-lfc_threshold, lfc_threshold),
                   linetype = "dashed", colour = "grey40") +
        geom_vline(xintercept = c(-lfc_threshold, lfc_threshold),
                   linetype = "dashed", colour = "grey40") +
        facet_wrap(~Construct, scales = "free") +
        scale_colour_brewer(palette = "Set2") +
        labs(title = "LFC comparison for Joseph's DEGs not recovered by our analysis",
             x = "Joseph log2FoldChange", y = "Our log2FoldChange",
             colour = "Reason not called") +
        theme_bw(base_size = 11)

      print(p_scatter)
      ggsave("DEG_Recovery_LFC_Scatter.svg", p_scatter, width = 14, height = 10)
    }

    # --- Summary: median Joseph LFC for missed genes by category ---
    cat("\n=== Median |Joseph LFC| for missed genes by category ===\n")
    detail_all %>%
      dplyr::group_by(Construct, Category) %>%
      dplyr::summarise(n = n(),
                       median_joseph_lfc = round(median(abs(as.numeric(joseph_lfc)), na.rm = TRUE), 2),
                       .groups = "drop") %>%
      as.data.frame() %>%
      print()
  }

} else {
  cat("DEG recovery analysis requires: joseph_clusters (from cluster_comparison chunk) and de_results_list (from differential_expression chunk).\n")
}
```

```{r heatmap_auxin_responsive, fig.width=10, fig.height=6}
# Filter for genes differentially expressed in GUS_aux vs GUS
df_auxin_responsive <- df2 %>%
  filter(`Up_Down-GUS_aux` %in% c("UP", "Down"))

if (nrow(df_auxin_responsive) > 0) {
  cat("Auxin-responsive genes (GUS_aux DEGs):", nrow(df_auxin_responsive), "\n")

  df_heat_aux <- df_auxin_responsive %>%
    dplyr::select(all_of(counts_cols)) %>%
    as.matrix()
  rownames(df_heat_aux) <- df_auxin_responsive$Geneid

  svglite("Auxin_Responsive_heatmap.svg", width = 10, height = 6)
  pheatmap(
    df_heat_aux,
    scale = "row",
    show_rownames = FALSE,
    show_colnames = TRUE,
    cluster_cols = FALSE,
    cluster_rows = TRUE,
    main = "Auxin-Responsive Genes Heatmap"
  )
  dev.off()
}
```

## Volcano Plots

```{r volcano_plots, fig.width=10, fig.height=6}
library(ggrepel)

# Create volcano plot for each treatment
for (con in treatment_constructs) {
  l2fc_col <- paste0("log2FoldChange-", con)
  padj_col <- paste0("padj-", con)
  up_down_col <- paste0("Up_Down-", con)

  # Prepare plot data
  plot_data <- df2 %>%
    filter(!is.na(.data[[padj_col]]) & !is.na(.data[[l2fc_col]])) %>%
    mutate(
      neg_log10_padj = -log10(.data[[padj_col]]),
      regulation = ifelse(.data[[up_down_col]] == "UP", "Upregulated",
                          ifelse(.data[[up_down_col]] == "Down", "Downregulated", "Not significant"))
    )

  p <- ggplot(plot_data, aes_string(x = paste0("`", l2fc_col, "`"),
                                     y = "neg_log10_padj",
                                     col = "regulation")) +
    geom_vline(xintercept = c(-lfc_threshold, lfc_threshold), col = 'gray', linetype = 'dashed') +
    geom_hline(yintercept = -log10(padj_threshold), col = 'gray', linetype = 'dashed') +
    geom_point(size = 1, alpha = 0.7) +
    scale_color_manual(values = c('Downregulated' = '#639FC4',
                                  'Not significant' = 'gray',
                                  'Upregulated' = '#FFB300')) +
    labs(color = con,
         x = expression('log'[2]*'FC'),
         y = expression('-log'[10]*'adjusted p-value'),
         title = paste("Volcano Plot:", con, "vs", control_construct)) +
    theme_classic()

  print(p)

  svglite(paste0("Volcano_", con, ".svg"), width = 10, height = 6)
  print(p)
  dev.off()
}
```

## Expression Boxplots for Selected Genes

```{r boxplots_selected_genes, fig.width=12, fig.height=10}
# Define genes of interest (modify as needed)
# Example: top 10 most significantly DE genes across all constructs
genes_of_interest <- df2 %>%
  filter(if_any(all_of(ud_cols), ~ . %in% c("UP", "Down"))) %>%
  head(20) %>%
  pull(Geneid)

if (length(genes_of_interest) > 0) {
  # Get sample columns (excluding averages)
  sample_cols <- sample_metadata$sample_name

  # Reshape data for plotting
  df_long <- df2 %>%
    filter(Geneid %in% genes_of_interest) %>%
    dplyr::select(Geneid, all_of(sample_cols)) %>%
    pivot_longer(
      cols = all_of(sample_cols),
      names_to = "Sample",
      values_to = "Normalized_Reads"
    ) %>%
    mutate(
      Construct = gsub("-\\d+$", "", Sample),
      Construct = factor(Construct, levels = all_constructs)
    )

  ggplot(df_long, aes(x = Construct, y = Normalized_Reads)) +
    geom_boxplot() +
    facet_wrap(~ Geneid, scales = "free_y", ncol = 4) +
    theme_bw(base_size = 10) +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    labs(
      x = "Construct",
      y = "Normalized Reads",
      title = "Expression of Selected Genes Across Constructs"
    )
}
```

## UpSet Plots

```{r upset_plots, fig.width=10, fig.height=6}
library(UpSetR)

# Prepare gene sets for UP-regulated genes
up_genes_list <- list()
down_genes_list <- list()

for (con in treatment_constructs) {
  up_down_col <- paste0("Up_Down-", con)

  up_genes_list[[con]] <- df2 %>%
    filter(.data[[up_down_col]] == "UP") %>%
    pull(Geneid)

  down_genes_list[[con]] <- df2 %>%
    filter(.data[[up_down_col]] == "Down") %>%
    pull(Geneid)
}

# UP-regulated UpSet plot with enhanced formatting
if (any(sapply(up_genes_list, length) > 0)) {
  upset_matrix_up <- fromList(up_genes_list)

  svglite("UpSet_UP_regulated.svg", width = 10, height = 6)
  print(upset(
    upset_matrix_up,
    sets = treatment_constructs,
    keep.order = TRUE,
    order.by = "freq",
    nintersects = 40,
    mb.ratio = c(0.60, 0.40),
    decreasing = TRUE,
    point.size = 4,
    line.size = 1.5,
    text.scale = 1,
    mainbar.y.label = "UP-regulated gene intersections",
    sets.x.label = "Genes per construct"
  ))
  dev.off()

  upset(
    upset_matrix_up,
    sets = treatment_constructs,
    keep.order = TRUE,
    order.by = "freq",
    nintersects = 40,
    mb.ratio = c(0.60, 0.40),
    decreasing = TRUE,
    point.size = 4,
    line.size = 1.5,
    text.scale = 1,
    mainbar.y.label = "UP-regulated gene intersections",
    sets.x.label = "Genes per construct"
  )
}

# DOWN-regulated UpSet plot with enhanced formatting
if (any(sapply(down_genes_list, length) > 0)) {
  upset_matrix_down <- fromList(down_genes_list)

  svglite("UpSet_DOWN_regulated.svg", width = 10, height = 6)
  print(upset(
    upset_matrix_down,
    sets = treatment_constructs,
    keep.order = TRUE,
    order.by = "freq",
    nintersects = 40,
    mb.ratio = c(0.60, 0.40),
    decreasing = TRUE,
    point.size = 5,
    line.size = 2,
    text.scale = 1,
    mainbar.y.label = "DOWN-regulated gene intersections",
    sets.x.label = "Genes per construct"
  ))
  dev.off()

  upset(
    upset_matrix_down,
    sets = treatment_constructs,
    keep.order = TRUE,
    order.by = "freq",
    nintersects = 40,
    mb.ratio = c(0.60, 0.40),
    decreasing = TRUE,
    point.size = 5,
    line.size = 2,
    text.scale = 1,
    mainbar.y.label = "DOWN-regulated gene intersections",
    sets.x.label = "Genes per construct"
  )
}
```

## Venn Diagrams

```{r venn_diagrams, fig.width=10, fig.height=8}
# Install eulerr if needed
# install.packages("eulerr")
library(eulerr)

# UP-regulated Euler diagram
if (any(sapply(up_genes_list, length) > 0)) {
  fit_up <- euler(up_genes_list)

  svglite("Venn_UP_regulated.svg", width = 10, height = 8)
  plot(fit_up,
       fills = list(fill = c("#66c2a5","#fc8d62","#8da0cb","#e78ac3","#a6d854","#ffd92f"), alpha = 0.6),
       labels = list(font = 2),
       main = "UP-Regulated Gene Overlaps",
       edges = TRUE)
  dev.off()

  plot(fit_up,
       fills = list(fill = c("#66c2a5","#fc8d62","#8da0cb","#e78ac3","#a6d854","#ffd92f"), alpha = 0.6),
       labels = list(font = 2),
       main = "UP-Regulated Gene Overlaps",
       edges = TRUE)
}

# DOWN-regulated Euler diagram
if (any(sapply(down_genes_list, length) > 0)) {
  fit_down <- euler(down_genes_list)

  svglite("Venn_DOWN_regulated.svg", width = 10, height = 8)
  plot(fit_down,
       fills = list(fill = c("#66c2a5","#fc8d62","#8da0cb","#e78ac3","#a6d854","#ffd92f"), alpha = 0.6),
       labels = list(font = 2),
       main = "DOWN-Regulated Gene Overlaps",
       edges = TRUE)
  dev.off()

  plot(fit_down,
       fills = list(fill = c("#66c2a5","#fc8d62","#8da0cb","#e78ac3","#a6d854","#ffd92f"), alpha = 0.6),
       labels = list(font = 2),
       main = "DOWN-Regulated Gene Overlaps",
       edges = TRUE)
}
```

## Alternative Venn Diagrams with ggVennDiagram

```{r venn_ggvenn, fig.width=10, fig.height=8}
# install.packages("ggVennDiagram")
library(ggVennDiagram)

# For a subset of constructs (4-way comparison works best)
venn_constructs <- c("5D", "6D", "7D", "8D")
venn_up_list <- up_genes_list[venn_constructs]
venn_down_list <- down_genes_list[venn_constructs]

# UP-regulated ggVennDiagram
if (any(sapply(venn_up_list, length) > 0)) {
  p_venn_up <- ggVennDiagram(venn_up_list,
                              category.names = venn_constructs,
                              label = "count") +
    scale_fill_gradient(low = "white", high = "red") +
    labs(title = "UP-Regulated Genes")

  print(p_venn_up)
  ggsave("VennDiagram_UP_ggVenn.svg", plot = p_venn_up, height = 8, width = 10)
}

# DOWN-regulated ggVennDiagram
if (any(sapply(venn_down_list, length) > 0)) {
  p_venn_down <- ggVennDiagram(venn_down_list,
                                category.names = venn_constructs,
                                label = "count") +
    scale_fill_gradient(low = "white", high = "blue") +
    labs(title = "DOWN-Regulated Genes")

  print(p_venn_down)
  ggsave("VennDiagram_DOWN_ggVenn.svg", plot = p_venn_down, height = 8, width = 10)
}
```

## GO Term Enrichment Analysis

### GO Enrichment by Construct

```{r go_enrichment_construct, fig.width=12, fig.height=10}
library(clusterProfiler)
library(org.At.tair.db)
library(GOSemSim)

# Perform GO enrichment for each construct's UP-regulated genes
all_enrichment_results <- list()

for (con in treatment_constructs) {
  up_down_col <- paste0("Up_Down-", con)

  # Get UP-regulated genes
  up_genes <- df2 %>%
    filter(.data[[up_down_col]] == "UP") %>%
    pull(Geneid)

  if (length(up_genes) >= 5) {  # Need minimum genes for enrichment
    ego <- tryCatch({
      enrichGO(
        gene = up_genes,
        OrgDb = org.At.tair.db,
        keyType = "TAIR",
        ont = "BP",
        pAdjustMethod = "BH",
        pvalueCutoff = 0.05,
        qvalueCutoff = 0.05
      )
    }, error = function(e) {
      message(sprintf("No enrichment results for %s: %s", con, e$message))
      return(NULL)
    })

    if (!is.null(ego) && nrow(as.data.frame(ego)) > 0) {
      ego_df <- as.data.frame(ego) %>%
        arrange(p.adjust) %>%
        head(15)
      ego_df$Construct <- con
      all_enrichment_results[[con]] <- ego_df
    }
  }
}

# Combine and plot if results exist
if (length(all_enrichment_results) > 0) {
  combined_enrichment <- bind_rows(all_enrichment_results)
  combined_enrichment$Construct <- factor(combined_enrichment$Construct,
                                          levels = treatment_constructs)

  # === Semantic Similarity Clustering ===
  # Create semantic data object for Arabidopsis
  hsGO <- godata('org.At.tair.db', ont = "BP")

  # Get unique GO IDs
  unique_go <- unique(combined_enrichment$ID)

  # Calculate pairwise semantic similarity
  sim_matrix <- mgoSim(unique_go, unique_go, semData = hsGO, measure = "Wang", combine = "BMA")

  # Handle single value case
  if (is.numeric(sim_matrix) && length(sim_matrix) == 1) {
    sim_matrix <- outer(unique_go, unique_go, Vectorize(function(x, y) {
      goSim(x, y, semData = hsGO, measure = "Wang")
    }))
  }

  # Convert to distance and cluster
  dist_matrix <- as.dist(1 - sim_matrix)
  hc <- hclust(dist_matrix, method = "average")
  ordered_go <- hc$labels[hc$order]

  # Reorder GO terms by clustering
  go_order <- combined_enrichment %>%
    distinct(ID, Description) %>%
    arrange(match(ID, ordered_go)) %>%
    pull(Description)

  combined_enrichment$Description <- factor(combined_enrichment$Description, levels = go_order)

  # Plot with semantic similarity ordering
  p_go <- ggplot(combined_enrichment, aes(
    x = Construct,
    y = Description,
    size = Count,
    color = -log10(p.adjust)
  )) +
    geom_point() +
    scale_size(range = c(4, 12)) +
    scale_color_gradientn(colours = c("#440F57", "#424285", "#2C748E", "#37B977", "#FFCB27")) +
    theme_bw() +
    theme(
      axis.text.x = element_text(angle = 45, hjust = 1),
      axis.title.x = element_blank(),
      axis.title.y = element_blank(),
      axis.text.y = element_text(size = 8)
    ) +
    labs(title = "GO Term Enrichment (UP-regulated genes) - Semantically Clustered")

  print(p_go)

  ggsave("GO_enrichment_UP_semantically_clustered.svg", plot = p_go, width = 12, height = 10)

  # Save results
  write.csv(combined_enrichment, "GO_enrichment_by_construct.csv", row.names = FALSE, quote = TRUE)
}
```

### GO Enrichment by Gene Cluster

```{r go_enrichment_cluster, fig.width=12, fig.height=10}
# Only run if we have cluster information
if ("Cluster" %in% colnames(df2)) {

  # Get unique clusters
  clusters <- unique(df2$Cluster[!is.na(df2$Cluster)])

  cluster_enrichment_results <- list()

  for (clust in clusters) {
    # Get genes in this cluster
    cluster_genes <- df2 %>%
      filter(Cluster == clust) %>%
      pull(Geneid)

    if (length(cluster_genes) >= 5) {
      ego_clust <- tryCatch({
        enrichGO(
          gene = cluster_genes,
          OrgDb = org.At.tair.db,
          keyType = "TAIR",
          ont = "BP",
          pAdjustMethod = "BH",
          pvalueCutoff = 0.05,
          qvalueCutoff = 0.05
        )
      }, error = function(e) {
        message(sprintf("No enrichment for cluster %s", clust))
        return(NULL)
      })

      if (!is.null(ego_clust) && nrow(as.data.frame(ego_clust)) > 0) {
        ego_clust_df <- as.data.frame(ego_clust) %>%
          arrange(p.adjust) %>%
          head(5)
        ego_clust_df$Cluster <- as.character(clust)
        cluster_enrichment_results[[as.character(clust)]] <- ego_clust_df
      }
    }
  }

  # Combine and plot
  if (length(cluster_enrichment_results) > 0) {
    combined_cluster_enrichment <- bind_rows(cluster_enrichment_results)

    # Semantic similarity clustering
    unique_go_clust <- unique(combined_cluster_enrichment$ID)

    if (length(unique_go_clust) > 1) {
      sim_matrix_clust <- mgoSim(unique_go_clust, unique_go_clust,
                                  semData = hsGO, measure = "Wang", combine = "BMA")

      if (is.numeric(sim_matrix_clust) && length(sim_matrix_clust) == 1) {
        sim_matrix_clust <- outer(unique_go_clust, unique_go_clust, Vectorize(function(x, y) {
          goSim(x, y, semData = hsGO, measure = "Wang")
        }))
      }

      dist_matrix_clust <- as.dist(1 - sim_matrix_clust)
      hc_clust <- hclust(dist_matrix_clust, method = "average")
      ordered_go_clust <- hc_clust$labels[hc_clust$order]

      go_order_clust <- combined_cluster_enrichment %>%
        distinct(ID, Description) %>%
        arrange(match(ID, ordered_go_clust)) %>%
        pull(Description)

      combined_cluster_enrichment$Description <- factor(combined_cluster_enrichment$Description,
                                                        levels = go_order_clust)
    }

    p_go_cluster <- ggplot(combined_cluster_enrichment, aes(
      x = Cluster,
      y = Description,
      size = Count,
      color = -log10(p.adjust)
    )) +
      geom_point() +
      scale_size(range = c(4, 12)) +
      scale_color_gradientn(colours = c("#440F57", "#424285", "#2C748E", "#37B977", "#FFCB27")) +
      theme_bw() +
      theme(
        axis.text.x = element_text(angle = 0, hjust = 0.5),
        axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        axis.text.y = element_text(size = 8)
      ) +
      labs(title = "GO Term Enrichment by Gene Cluster")

    print(p_go_cluster)

    ggsave("GO_enrichment_by_cluster.svg", plot = p_go_cluster, width = 12, height = 10)
    write.csv(combined_cluster_enrichment, "GO_enrichment_by_cluster.csv",
              row.names = FALSE, quote = TRUE)
  }
}
```

## Inverse Correlation Analysis

```{r inverse_correlation}
library(tibble)

# Find genes inversely correlated with a reference gene
# Modify reference_gene as needed

reference_gene <- "AT1G15050"  # Example: modify to your gene of interest

# Get sample columns
sample_cols <- sample_metadata$sample_name

# Create expression matrix for DEGs
df_DEGs_expr <- df2 %>%
  filter(if_any(all_of(ud_cols), ~ . %in% c("UP", "Down"))) %>%
  dplyr::select(Geneid, all_of(sample_cols))

if (reference_gene %in% df_DEGs_expr$Geneid) {
  expr_mat <- df_DEGs_expr %>%
    column_to_rownames("Geneid") %>%
    as.matrix()

  ref_expr <- as.numeric(expr_mat[reference_gene, ])

  # Calculate correlations
  gene_cor <- apply(expr_mat, 1, function(x) {
    cor(x, ref_expr, use = "pairwise.complete.obs", method = "pearson")
  })

  # Calculate p-values
  p_vals <- apply(expr_mat, 1, function(x) {
    test_result <- cor.test(x, ref_expr, use = "pairwise.complete.obs", method = "pearson")
    test_result$p.value
  })

  # Adjust p-values
  p_adj <- p.adjust(p_vals, method = "BH")

  # Combine results
  cor_results <- data.frame(
    Geneid = rownames(expr_mat),
    correlation = gene_cor,
    p_value = p_vals,
    p_adj = p_adj
  )

  # Filter for inversely correlated genes
  inversely_correlated <- cor_results %>%
    filter(correlation < -0.5 & p_adj < 0.05)

  cat("\nGenes inversely correlated with", reference_gene, ":\n")
  cat("Number of inversely correlated genes:", nrow(inversely_correlated), "\n")

  if (nrow(inversely_correlated) > 0) {
    write.csv(inversely_correlated,
              file = paste0(reference_gene, "_inverse_correlations.csv"),
              row.names = FALSE, quote = TRUE)
  }
}
```

## Promoter Motif Analysis

### MCAST Motif Cluster Analysis

```{r mcast_analysis, eval=FALSE}
# NOTE: This section requires MCAST output files
# Run MCAST externally on promoter sequences, then analyze here

library(Biostrings)

# Function to find motif occurrences by regex
find_motif_occurrences <- function(seq_string, motif_regex, orientation = "+") {
  seq_string <- toupper(seq_string)
  matches <- gregexpr(pattern = motif_regex, text = seq_string, perl = TRUE)

  start_positions <- as.integer(matches[[1]])
  if (start_positions[1] == -1) {
    return(data.frame(start=integer(0), end=integer(0), orientation=character(0)))
  } else {
    match_lengths <- attr(matches[[1]], "match.length")
    end_positions <- start_positions + match_lengths - 1
    return(data.frame(
      start = start_positions,
      end   = end_positions,
      orientation = orientation
    ))
  }
}

# Check if MCAST output exists
mcast_file <- "Clustering/Motif_Analysis/mcast_output.tsv"
if (file.exists(mcast_file)) {

  # Read MCAST TSV
  mcast_df <- read.table(mcast_file,
                         header = TRUE,
                         sep = "\t",
                         stringsAsFactors = FALSE)

  all_hits_df <- data.frame()

  for (i in seq_len(nrow(mcast_df))) {
    seq_id        <- mcast_df$sequence_name[i]
    cluster_start <- mcast_df$start[i]
    cluster_seq   <- mcast_df$matched_sequence[i]

    # Find forward and reverse strand hits
    fwd_hits <- find_motif_occurrences(cluster_seq, "TGTC[ACGT]{2}", orientation="+")
    rev_hits <- find_motif_occurrences(cluster_seq, "[ACGT]{2}GACA", orientation="-")

    cluster_hits <- rbind(fwd_hits, rev_hits)
    if (nrow(cluster_hits) == 0) next

    cluster_hits <- cluster_hits[order(cluster_hits$start), ]
    cluster_hits$sequence_name <- seq_id
    cluster_hits$cluster_row   <- i
    cluster_hits$abs_start <- cluster_start + cluster_hits$start - 1
    cluster_hits$abs_end   <- cluster_start + cluster_hits$end   - 1

    # Extract motif sequence
    cluster_seq_upper <- toupper(cluster_seq)
    cluster_hits$motif_seq <- mapply(function(st, en, ori) {
      raw_sub <- substring(cluster_seq_upper, st, en)
      if (ori == "-") {
        as.character(reverseComplement(DNAString(raw_sub)))
      } else {
        raw_sub
      }
    }, cluster_hits$start, cluster_hits$end, cluster_hits$orientation)

    # Compute spacing to nearest neighbor
    n_hits <- nrow(cluster_hits)
    dist_to_right <- numeric(n_hits)
    dist_to_left  <- numeric(n_hits)

    for (j in seq_len(n_hits)) {
      if (j < n_hits) {
        dist_to_right[j] <- cluster_hits$abs_start[j+1] - cluster_hits$abs_end[j] - 1
      } else {
        dist_to_right[j] <- Inf
      }

      if (j > 1) {
        dist_to_left[j] <- cluster_hits$abs_start[j] - cluster_hits$abs_end[j-1] - 1
      } else {
        dist_to_left[j] <- Inf
      }
    }

    spacing_vec <- pmin(dist_to_left, dist_to_right, na.rm = TRUE)

    # Classify orientation (DR, IR, ER)
    classify_pair <- function(o1, o2) {
      if (o1 == o2) {
        return("DR")  # direct repeat
      } else if (o1 == "+" && o2 == "-") {
        return("IR")  # inverted repeat
      } else if (o1 == "-" && o2 == "+") {
        return("ER")  # everted repeat
      }
      return(NA_character_)
    }

    pair_type_vec <- rep(NA_character_, n_hits)

    for (j in seq_len(n_hits)) {
      left_d  <- dist_to_left[j]
      right_d <- dist_to_right[j]

      if (!is.finite(left_d) && !is.finite(right_d)) {
        pair_type_vec[j] <- NA
        next
      }

      if (left_d < right_d) {
        pair_type_vec[j] <- classify_pair(
          cluster_hits$orientation[j-1],
          cluster_hits$orientation[j]
        )
      } else if (right_d < left_d) {
        pair_type_vec[j] <- classify_pair(
          cluster_hits$orientation[j],
          cluster_hits$orientation[j+1]
        )
      } else if (is.finite(left_d) && left_d == right_d) {
        pair_type_vec[j] <- NA
      }
    }

    cluster_hits$spacing_to_nearest <- spacing_vec
    cluster_hits$pair_type_to_nearest <- pair_type_vec

    all_hits_df <- rbind(all_hits_df, cluster_hits)
  }

  # Save results
  write.csv(all_hits_df, "Motif_Analysis_All_Hits.csv", row.names = FALSE, quote = TRUE)

  # Summary by cluster
  summary_by_cluster <- all_hits_df %>%
    group_by(sequence_name, cluster_row) %>%
    summarise(num_hits = n(),
              avg_spacing = mean(spacing_to_nearest, na.rm=TRUE),
              .groups = "drop")

  write.csv(summary_by_cluster, "Motif_Analysis_Summary.csv", row.names = FALSE, quote = TRUE)

  cat("Motif analysis complete. Results saved.\n")
}
```

### Repeat Orientation Analysis

```{r repeat_orientation, fig.width=8, fig.height=6, eval=FALSE}
# Analyze repeat orientation patterns (DR/IR/ER)

if (exists("all_hits_df") && nrow(all_hits_df) > 0) {

  # Count orientation patterns
  pair_counts <- all_hits_df %>%
    filter(!is.na(pair_type_to_nearest)) %>%
    group_by(pair_type_to_nearest) %>%
    summarise(num_motifs = n(), .groups = "drop")

  p_orientation <- ggplot(pair_counts, aes(x = pair_type_to_nearest, y = num_motifs,
                                            fill = pair_type_to_nearest)) +
    geom_bar(stat = "identity") +
    labs(x = "Repeat Orientation",
         y = "Number of Motifs",
         title = "AuxRE Repeat Orientation Patterns") +
    theme_minimal()

  print(p_orientation)
  ggsave("Repeat_Orientation_Barplot.svg", plot = p_orientation, width = 8, height = 6)

  # Statistical test for orientation differences between clusters
  if ("Cluster" %in% colnames(df2)) {
    # Merge cluster info with motif data
    all_hits_with_cluster <- all_hits_df %>%
      left_join(df2 %>% select(Geneid, Cluster), by = c("sequence_name" = "Geneid"))

    # Create contingency table
    orientation_table <- all_hits_with_cluster %>%
      filter(!is.na(pair_type_to_nearest) & !is.na(Cluster)) %>%
      group_by(Cluster, pair_type_to_nearest) %>%
      summarise(count = n(), .groups = "drop") %>%
      pivot_wider(names_from = pair_type_to_nearest, values_from = count, values_fill = 0)

    if (nrow(orientation_table) > 1) {
      test_matrix <- as.matrix(orientation_table[, -1])
      rownames(test_matrix) <- orientation_table$Cluster

      # Chi-square test
      chisq_result <- chisq.test(test_matrix)
      print(chisq_result)

      cat("\nExpected values:\n")
      print(chisq_result$expected)
    }
  }
}
```

### Coupling Element Identification

```{r coupling_elements, eval=FALSE}
# Identify and extract coupling elements (clusters of AuxREs within 30bp)

library(Biostrings)

# Function to find AuxRE motifs
find_auxre_motifs <- function(sequence) {
  sequence <- as.character(sequence)
  auxre_fwd <- "TGTC[ACGT]{2}"
  auxre_rev <- "[ACGT]{2}GACA"

  fwd_matches <- gregexpr(auxre_fwd, sequence, perl=TRUE)[[1]]
  rev_matches <- gregexpr(auxre_rev, sequence, perl=TRUE)[[1]]

  motif_positions <- data.frame(
    start = c(fwd_matches, rev_matches),
    end = c(fwd_matches + 5, rev_matches + 5),
    orientation = c(rep("+", length(fwd_matches)), rep("-", length(rev_matches)))
  )

  motif_positions <- motif_positions[motif_positions$start > 0, ]
  return(motif_positions)
}

# Function to find clusters (≤30bp spacing)
find_clusters <- function(motif_positions) {
  if (nrow(motif_positions) < 2) {
    return(NULL)
  }

  motif_positions <- motif_positions[order(motif_positions$start), ]
  clusters <- list()
  current_cluster <- c(motif_positions$start[1])

  for (i in 2:nrow(motif_positions)) {
    prev_motif <- motif_positions$start[i-1]
    curr_motif <- motif_positions$start[i]

    if ((curr_motif - prev_motif) <= 30) {
      current_cluster <- c(current_cluster, curr_motif)
    } else {
      if (length(current_cluster) > 1) {
        clusters <- append(clusters, list(range(current_cluster)))
      }
      current_cluster <- c(curr_motif)
    }
  }

  if (length(current_cluster) > 1) {
    clusters <- append(clusters, list(range(current_cluster)))
  }

  return(clusters)
}

# Function to extract cluster sequences with flanking regions
extract_cluster_sequences <- function(sequence, clusters) {
  extracted_sequences <- list()

  for (cluster in clusters) {
    cluster_start <- max(cluster[1] - 30, 1)
    cluster_end <- min(cluster[2] + 30, nchar(sequence))

    extracted_seq <- substr(sequence, cluster_start, cluster_end)
    extracted_sequences <- append(extracted_sequences, list(extracted_seq))
  }

  return(extracted_sequences)
}

# Check if promoter FASTA file exists
promoter_fasta <- "Clustering/promoter_sequences.fasta"
if (file.exists(promoter_fasta)) {
  fasta_file <- readDNAStringSet(promoter_fasta, format="fasta")
  seq_list <- as.list(fasta_file)
  seq_names <- names(fasta_file)

  output_sequences <- list()

  for (i in seq_along(seq_list)) {
    gene_id <- seq_names[i]
    sequence <- seq_list[[i]]

    motif_positions <- find_auxre_motifs(sequence)

    if (nrow(motif_positions) < 2) {
      next
    }

    clusters <- find_clusters(motif_positions)

    if (length(clusters) == 0) {
      next
    }

    extracted_seqs <- extract_cluster_sequences(sequence, clusters)

    for (j in seq_along(extracted_seqs)) {
      output_sequences[[paste0(gene_id, "_cluster", j)]] <- extracted_seqs[[j]]
    }
  }

  # Save coupling elements as FASTA
  if (length(output_sequences) > 0) {
    output_fasta <- DNAStringSet(output_sequences)
    names(output_fasta) <- names(output_sequences)
    writeXStringSet(output_fasta, "auxre_coupling_elements.fasta", format="fasta")
    cat("Coupling elements extracted and saved to auxre_coupling_elements.fasta\n")
  }
}
```

### SEA Motif Enrichment Comparison

```{r sea_comparison, fig.width=10, fig.height=8, eval=FALSE}
# Compare SEA motif enrichment results between gene lists/clusters

# Check for SEA output files
sea_files <- list.files("Clustering/Motif_Analysis/Coupling_Elements",
                        pattern = "_coupling_SEA.*\\.tsv$", full.names = TRUE)

if (length(sea_files) >= 2) {

  # Read first two SEA results for comparison
  sea_list1 <- read.table(sea_files[1], header=TRUE, sep="\t", stringsAsFactors=FALSE)
  sea_list2 <- read.table(sea_files[2], header=TRUE, sep="\t", stringsAsFactors=FALSE)

  # Merge based on motif ID
  sea_merged <- full_join(sea_list1, sea_list2, by="ID", suffix=c("_list1", "_list2"))

  # Handle NAs
  sea_merged$ENR_RATIO_list1[is.na(sea_merged$ENR_RATIO_list1)] <- 1
  sea_merged$ENR_RATIO_list2[is.na(sea_merged$ENR_RATIO_list2)] <- 1
  sea_merged$PVALUE_list1[is.na(sea_merged$PVALUE_list1)] <- 1
  sea_merged$PVALUE_list2[is.na(sea_merged$PVALUE_list2)] <- 1

  # Calculate log fold change
  sea_merged$logFC <- log2(sea_merged$ENR_RATIO_list2 / sea_merged$ENR_RATIO_list1)

  # Sort by absolute log-fold change
  sea_merged <- sea_merged[order(abs(sea_merged$logFC), decreasing=TRUE),]

  # Multiple testing correction
  sea_merged$adjusted_pvalue <- p.adjust(sea_merged$PVALUE_list1, method="fdr")

  # Volcano plot
  p_volcano <- ggplot(sea_merged, aes(x=logFC, y=-log10(adjusted_pvalue))) +
    geom_point(aes(color=adjusted_pvalue < 0.05)) +
    geom_vline(xintercept=0, linetype="dashed") +
    theme_minimal() +
    labs(title="Motif Enrichment Differences",
         x="Log2 Fold Change (List2 / List1)",
         y="-Log10 Adjusted P-value")

  print(p_volcano)
  ggsave("SEA_Motif_Enrichment_Volcano.svg", plot = p_volcano, width = 10, height = 8)

  # Bar plot of top differentially enriched motifs
  top_motifs <- head(sea_merged, 20)

  p_bar <- ggplot(top_motifs, aes(x=reorder(ID, logFC), y=logFC, fill=logFC > 0)) +
    geom_bar(stat="identity") +
    coord_flip() +
    labs(title="Differential Motif Enrichment",
         x="Motif ID", y="Log2 Fold Change (List2 / List1)") +
    theme_minimal()

  print(p_bar)
  ggsave("SEA_Motif_Enrichment_Barplot.svg", plot = p_bar, width = 10, height = 8)

  write.csv(sea_merged, "SEA_Motif_Comparison.csv", row.names = FALSE, quote = TRUE)
}
```

## TF Deacon Enrichment Analysis

```{r tf_deacon, fig.width=10, fig.height=10, eval=FALSE}
# Transcription factor family enrichment using DEACoN

library(scales)

# Check for TF Deacon output files
deacon_dir <- "TF_Deacon/ARFs"
if (dir.exists(deacon_dir)) {
  file_paths <- list.files(path = deacon_dir, pattern = "*.csv", full.names = TRUE)

  if (length(file_paths) > 0) {
    gene_list_names <- tools::file_path_sans_ext(basename(file_paths))

    # Read and combine all DEACoN results
    deacon_data <- map2_dfr(file_paths, gene_list_names, ~ read_csv(.x) %>%
                              mutate(Gene_List = .y))

    # Filter significant TFs
    pval_cutoff <- 0.001
    filtered <- deacon_data %>%
      filter(adj.pval < pval_cutoff)

    # Calculate total family size
    family_sizes <- deacon_data %>%
      group_by(family) %>%
      summarise(total_family_size = n_distinct(tf.id))

    # Fisher's combined p-value function
    fisher_combined_p <- function(pvalues) {
      chi_stat <- -2 * sum(log(pvalues))
      df <- 2 * length(pvalues)
      pchisq(chi_stat, df, lower.tail = FALSE)
    }

    # Summarize by gene list and family
    summary_df <- filtered %>%
      group_by(Gene_List, family) %>%
      summarise(
        n_significant = n(),
        fisher_p = fisher_combined_p(pval),
        .groups = "drop"
      )

    # Add family sizes and normalize
    summary_df <- summary_df %>%
      left_join(family_sizes, by = "family") %>%
      mutate(
        normalized_size = n_significant / total_family_size,
        neglog10_fisher_p = -log10(fisher_p),
        neglog10_fisher_p = ifelse(is.infinite(neglog10_fisher_p), 300, neglog10_fisher_p),
        family = ifelse(is.na(family), "Undefined", family)
      )

    # Hierarchical clustering
    clust_matrix <- summary_df %>%
      select(Gene_List, family, neglog10_fisher_p) %>%
      pivot_wider(names_from = Gene_List, values_from = neglog10_fisher_p, values_fill = 0) %>%
      column_to_rownames(var = "family") %>%
      as.matrix()

    row_clust <- hclust(dist(clust_matrix))

    summary_df <- summary_df %>%
      mutate(family = factor(family, levels = row_clust$labels[row_clust$order]))

    # Plot
    p_tf <- ggplot(summary_df, aes(x = Gene_List, y = family)) +
      geom_point(aes(size = normalized_size, color = neglog10_fisher_p)) +
      scale_color_gradientn(colours = c("#0B0074","#6E0090","#B5296D","#E76E41","#FFCB27"),
                            limits = c(0, 50), oob = squish) +
      theme_minimal() +
      labs(
        title = "TF Family Enrichment across Gene Lists",
        x = "Gene List",
        y = "TF Family",
        color = "-log10(Fisher's p)",
        size = "Fraction of significant TFs"
      ) +
      theme(axis.text.x = element_text(angle = 45, hjust = 1))

    print(p_tf)
    ggsave("TF_Deacon_Enrichment.svg", plot = p_tf, width = 10, height = 10)
    write.csv(summary_df, "TF_Deacon_Summary.csv", row.names = FALSE, quote = TRUE)
  }
}
```

## External Dataset Integration

### Cell Type-Specific Expression Data

```{r cell_type_specific, fig.width=12, fig.height=10, eval=FALSE}
# Overlay DEGs with cell type-specific expression data

cell_type_file <- "Other_Datasets/Cell_Type_Specific_Data_auxin_responsive_BB.csv"
if (file.exists(cell_type_file)) {
  cell_type_specf <- read.csv(cell_type_file, check.names = FALSE)

  # Remove unwanted samples (if needed)
  cell_type_specf <- cell_type_specf[, 1:10]

  # Define DEG sets based on your analysis
  # Example: all upregulated genes
  deg_genes <- df2 %>%
    filter(if_any(all_of(ud_cols), ~ . %in% c("UP"))) %>%
    pull(Geneid)

  # Subset cell-type data to your DEGs
  cell_type_subset <- cell_type_specf[cell_type_specf$GeneID %in% deg_genes, ]

  if (nrow(cell_type_subset) > 0) {
    # Create expression matrix
    expr_mat <- as.matrix(cell_type_subset[, 3:10])
    rownames(expr_mat) <- cell_type_subset$GeneID

    # Heatmap
    p_cell_type <- pheatmap(
      expr_mat,
      scale = "row",
      main = "Cell Type-Specific Expression of DEGs",
      show_rownames = FALSE,
      show_colnames = TRUE,
      cluster_cols = FALSE,
      cluster_rows = TRUE
    )

    ggsave("Cell_Type_Specific_Expression.svg", plot = p_cell_type, width = 12, height = 10)
  }
}
```

### Okushima Dataset Comparison

```{r okushima_comparison, eval=FALSE}
# Compare with Okushima 2005 ARF mutant data

okushima_file <- "Other_Datasets/Okushima2005.csv"
if (file.exists(okushima_file)) {
  okushima_data <- read.csv(okushima_file, check.names = FALSE)

  # Get your DEGs
  deg_genes <- df2 %>%
    filter(if_any(all_of(ud_cols), ~ . %in% c("UP", "Down"))) %>%
    pull(Geneid)

  # Subset Okushima data
  okushima_subset <- okushima_data[okushima_data$GeneID %in% deg_genes, ]

  if (nrow(okushima_subset) > 0) {
    # Overlap statistics
    overlap_count <- length(intersect(deg_genes, okushima_data$GeneID))
    total_genes <- 27000  # Arabidopsis genome size

    # Fisher's exact test
    cont_table <- matrix(c(
      overlap_count,
      length(deg_genes) - overlap_count,
      nrow(okushima_data) - overlap_count,
      total_genes - (length(deg_genes) + nrow(okushima_data) - overlap_count)
    ), nrow = 2)

    fisher_result <- fisher.test(cont_table, alternative = "greater")
    cat("\n=== Overlap with Okushima Dataset ===\n")
    cat("Overlap:", overlap_count, "genes\n")
    cat("Fisher's exact test p-value:", fisher_result$p.value, "\n")

    write.csv(okushima_subset, "Okushima_Overlap_Genes.csv", row.names = FALSE, quote = TRUE)
  }
}
```

### Dataset Overlap Venn Diagrams

```{r dataset_overlap_venn, fig.width=8, fig.height=8, eval=FALSE}
# Venn diagram comparing your DEGs with external datasets

library(ggVennDiagram)

# Your DEGs
your_degs <- df2 %>%
  filter(if_any(all_of(ud_cols), ~ . %in% c("UP", "Down"))) %>%
  pull(Geneid)

# Load external dataset gene lists (if available)
external_lists <- list(
  "Your_DEGs" = your_degs
)

# Add Okushima if available
if (file.exists("Other_Datasets/Auxin_Induced_Okushima.csv")) {
  okushima_list <- read.csv("Other_Datasets/Auxin_Induced_Okushima.csv")
  external_lists[["Okushima"]] <- okushima_list$Geneid
}

# Add cell-type specific if available
if (file.exists("Other_Datasets/Cell_Type_Specific_Data_auxin_responsive_BB.csv")) {
  cell_type_list <- read.csv("Other_Datasets/Cell_Type_Specific_Data_auxin_responsive_BB.csv")
  external_lists[["Cell_Type"]] <- cell_type_list$GeneID
}

if (length(external_lists) >= 2) {
  p_venn_ext <- ggVennDiagram(external_lists, label_alpha = 0) +
    labs(title = "Dataset Overlap Analysis") +
    scale_fill_gradient(low = "white", high = "#83c441") +
    theme(legend.position = "none")

  print(p_venn_ext)
  ggsave("Dataset_Overlap_Venn.svg", plot = p_venn_ext, width = 8, height = 8)
}
```

## Session Info

```{r session_info}
sessionInfo()
```
